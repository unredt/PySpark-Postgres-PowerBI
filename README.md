# Pipeline para an√°lise de 67.5 milh√µes de registros  

## üìå APRESENTA√á√ÉO
An√°lise de dados de uma tabela com 67.5 milh√µes de linhas.
O objetivo deste projeto foi aprender de maneira pr√°tica a utiliza√ß√£o de PySpark
para trabalhar com grande quantidade de dados. Utilizei o Gemini como tutor para:
1- aprender PySpark
2- aprender boas pr√°ticas de An√°lise de Dados

O projeto envolve ingest√£o de dados em larga escala com PySpark,
armazenamento em Postgre e visualiza√ß√£o com Power BI.

## Pipeline
1. Ingest√£o de dados com PySpark
2. Limpeza, An√°lise, Novas tabelas
3. Armazenamento de novas tabelas
4. Ingest√£o dos dados no Power BI pelo Postgres para visualiza√ß√£o em dashboards

## Tecnologias Utilizadas
- Python (PySpark)
- PostgreSQL
- Power BI

## Dashboards
Os dashboards foram constru√≠dos no Power BI a partir das tabelas
constru√≠das no Python e armazenadas no Postgres
