# Pipeline para an√°lise de 67.5 milh√µes de registros  

## üìå APRESENTA√á√ÉO
An√°lise de dados de uma tabela com 67.5 milh√µes de linhas.
O objetivo deste projeto foi aprender de maneira pr√°tica a utiliza√ß√£o de PySpark
para trabalhar com grande quantidade de dados. Utilizei o Gemini como tutor para:
1- aprender PySpark
2- aprender boas pr√°ticas de An√°lise de Dados

O projeto envolve ingest√£o de dados em larga escala com PySpark,
armazenamento em Postgre e visualiza√ß√£o com Power BI.

## Pipeline
1. Ingest√£o de dados com PySpark
2. Limpeza, An√°lise, Novas tabelas
3. Armazenamento de novas tabelas
4. Ingest√£o dos dados no Power BI pelo Postgres para visualiza√ß√£o em dashboards

## Tecnologias Utilizadas
- Python (PySpark)
- PostgreSQL
- Power BI

## Dashboards
Os dashboards abaixo foram constru√≠dos no Power BI a partir das tabelas
constru√≠das no Python e armazenadas no Postgres


<img width="1412" height="792" alt="BI_Vendas" src="https://github.com/user-attachments/assets/7904205f-7a82-4eb0-8f2e-f85d4a4b41c4" />

<img width="1410" height="793" alt="BI_M√©tricas_sem_outlier" src="https://github.com/user-attachments/assets/70900355-aaa4-4c71-a826-c3a6d4f4da9d" />

<img width="1409" height="792" alt="BI_M√©tricas_com_outlier" src="https://github.com/user-attachments/assets/5bf4e27f-995b-4f0a-aff1-f09d8d72fb0f" />

<img width="1409" height="791" alt="BI_Produtos_Populares" src="https://github.com/user-attachments/assets/223b4c2e-82e2-497d-95e1-921cbe31d592" />

